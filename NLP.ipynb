{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVZPypEy8xHY"
      },
      "source": [
        "## Установка всех необходимых библиотек"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCW4qUMeJ2h7"
      },
      "source": [
        "# Importing needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rotdZhx4FQJt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\Desktop\\Outpeer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\HP\\Desktop\\Outpeer\\.venv\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
            "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from TTS.api import TTS\n",
        "import os\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edjMcBheJ--D"
      },
      "source": [
        "# OpenAI API Key (unique for every account)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO1cX5S0FOez"
      },
      "outputs": [],
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn0qwkw3KGYC"
      },
      "source": [
        "# Background Music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RPsNXEcFeVsh"
      },
      "outputs": [],
      "source": [
        "# 1) Background music selection\n",
        "# --------------------------------\n",
        "# Map certain theme keywords to audio files\n",
        "THEME_MUSIC_MAP = {\n",
        "    \"space\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\space.wav\",\n",
        "    \"fantastic\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\fantasy.wav\",\n",
        "    \"medieval\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\medieval.wav\",\n",
        "    \"horror\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\horror.wav\",\n",
        "    \"sea\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\sea.wav\",\n",
        "    \"sci-fi\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\sci-fi.wav\",\n",
        "    \"forest\": \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\day_forest.wav\"\n",
        "    }\n",
        "\n",
        "DEFAULT_BG_MUSIC = \"C:\\\\Users\\\\HP\\\\Desktop\\\\Outpeer\\\\NLP_Project\\\\background_sound\\\\fairy_tail_slow.wav\"  # fallback if no matching theme\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQJagAPAKSlz"
      },
      "source": [
        "# Background Music Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ol6-wvdmeWpr"
      },
      "outputs": [],
      "source": [
        "def pick_background_music(themes):\n",
        "    \"\"\"\n",
        "    Given the user-input themes (string),\n",
        "    determine which background music file to use.\n",
        "\n",
        "    If multiple themes match, we'll pick the first one we find.\n",
        "    If none match, return the default.\n",
        "    \"\"\"\n",
        "    # Make the theme input lowercase for matching\n",
        "    themes_lower = themes.lower()\n",
        "\n",
        "    for key, music_file in THEME_MUSIC_MAP.items():\n",
        "        if key in themes_lower:\n",
        "            return music_file\n",
        "\n",
        "    # If no matches, return default music\n",
        "    return DEFAULT_BG_MUSIC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUuSUq1-Kcyk"
      },
      "source": [
        "# Fairy Tale Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RxhFE8keCmLc"
      },
      "outputs": [],
      "source": [
        "# 2) Fairy tale generation\n",
        "# --------------------------------\n",
        "def generate_fairy_tale():\n",
        "    \"\"\"\n",
        "    Prompts the user for custom input, then uses OpenAI ChatCompletion\n",
        "    to generate a fairy tale in Russian.\n",
        "    Returns the fairy tale text (string) and user themes.\n",
        "    \"\"\"\n",
        "    user_prompt = input(\"Enter an initial scenario or prompt for your fairy tale: \")\n",
        "    main_character = input(\"Who is your main character? \")\n",
        "    themes = input(\"List the themes (e.g., space, medieval, fantastic, sci-fi): \")\n",
        "\n",
        "    system_message = (\n",
        "        \"You are a creative AI specialized in crafting original fairy tales. \"\n",
        "        \"Write a complete story with a clear beginning, middle, and end. It should be relatively small story which includes 1000 words. \"\n",
        "        \"Use rich detail, do not end abruptly, and conclude with a final resolution. Change to Russian language.\"\n",
        "    )\n",
        "    user_message = (\n",
        "        f\"Initial Scenario: {user_prompt}\\n\"\n",
        "        f\"Main Character: {main_character}\\n\"\n",
        "        f\"Themes: {themes}\\n\\n\"\n",
        "        \"Please write the fairy tale using these elements, up to around 1000 words, ending conclusively.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model = \"gpt-4o-mini\",\n",
        "            messages = messages,\n",
        "            temperature = 0.7,\n",
        "            max_tokens = 10,    # For testing; increase if you need a longer story\n",
        "            top_p = 1.0,\n",
        "            frequency_penalty = 0.0,\n",
        "            presence_penalty = 0.0\n",
        "        )\n",
        "\n",
        "        fairy_tale = response.choices[0].message.content\n",
        "        return fairy_tale, themes\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c2hIj6_KffW"
      },
      "source": [
        "# Text to Speech Change using Coqui (Self-Generated Voice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p6FQU02rLPhO"
      },
      "outputs": [],
      "source": [
        "# 3) TTS synthesis (Coqui)\n",
        "# --------------------------------\n",
        "def text_to_speech_coqui(story_text, output_path=\"fairy_tale.wav\"):\n",
        "    \"\"\"\n",
        "    Uses a Coqui TTS model to synthesize speech from the given text.\n",
        "    Saves the audio to 'fairy_tale.wav' by default.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Choose a pretrained TTS model\n",
        "        model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "        tts = TTS(model_name=model_name)\n",
        "\n",
        "        # Convert text to an audio file\n",
        "        # For advanced usage, you might specify \"speaker\" if needed\n",
        "        # or \"speaker_wav\" for voice cloning, etc.\n",
        "        tts.tts_to_file(\n",
        "            text=story_text,\n",
        "            speaker_wav = \"Islam.wav\",\n",
        "            file_path=output_path,\n",
        "            language='ru'\n",
        "        )\n",
        "\n",
        "        print(f\"Fairy tale narration saved to '{output_path}'.\")\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during TTS: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORILzUW0Kuw3"
      },
      "source": [
        "# Adding Background Music to Generated Story"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l-1zwEMCGyQY"
      },
      "outputs": [],
      "source": [
        "# 4) Mixing narration + background\n",
        "# --------------------------------\n",
        "def mix_audio_files(narration_path, background_path, output_path, music_volume_db=-15, fade_out_ms=3000):\n",
        "    \"\"\"\n",
        "    Overlay the narration on top of background music:\n",
        "    1. Truncate/fade out background music to match narration length.\n",
        "    2. Lower background volume.\n",
        "    3. Save the mixed result as output_path.\n",
        "\n",
        "    :param narration_path: Path to the .wav file with TTS narration.\n",
        "    :param background_path: Path to the .wav file with background music.\n",
        "    :param output_path: Path to output the mixed audio.\n",
        "    :param music_volume_db: Amount to lower background volume (in dB).\n",
        "    :param fade_out_ms: Milliseconds of fade out on the background music at the end.\n",
        "    \"\"\"\n",
        "    # Load the narration\n",
        "    narration = AudioSegment.from_file(narration_path)\n",
        "    narration_duration = len(narration)  # in ms\n",
        "\n",
        "    # Load the background music\n",
        "    background = AudioSegment.from_file(background_path)\n",
        "\n",
        "    # Trim or repeat background to match (or exceed) the narration duration\n",
        "    # If music is shorter than narration, loop it or you can do something else:\n",
        "    if len(background) < narration_duration:\n",
        "        # Simple approach: loop the background until it matches or exceeds narration length\n",
        "        times_to_repeat = (narration_duration // len(background)) + 1\n",
        "        background = background * times_to_repeat\n",
        "\n",
        "    # Now fade out the last part of the background so it ends smoothly\n",
        "    background = background[:narration_duration].fade_out(fade_out_ms)\n",
        "\n",
        "    # Lower background volume\n",
        "    background = background + music_volume_db  # e.g., -10 dB\n",
        "\n",
        "    # Overlay the narration on top of the background\n",
        "    # The 'overlay' starts both tracks at the same time = 0ms\n",
        "    final_mix = background.overlay(narration, position=0)\n",
        "\n",
        "    # Export the final track\n",
        "    final_mix.export(output_path, format=\"wav\")\n",
        "    print(f\"Final mixed audio saved to '{output_path}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NB3dEl9LJgc"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuVe7BZ3J8Yc",
        "outputId": "1ae0131a-d2ac-4f43-8996-2ea3936deb99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== AI-Generated Fairy Tale (Russian) ===\n",
            "\n",
            "В далеком королевстве, спрятан\n",
            "Fairy tale narration saved to 'fairy_tale.wav'.\n",
            "Final mixed audio saved to 'final_fairy_tale_mix.wav'.\n",
            "\n",
            "=== Done! ===\n",
            "Your final narrated fairy tale with background music is: final_fairy_tale_mix.wav\n"
          ]
        }
      ],
      "source": [
        "# 5) Main workflow\n",
        "# --------------------------------\n",
        "def main():\n",
        "    # 1. Generate the story + capture the user’s theme(s)\n",
        "    fairy_tale, themes = generate_fairy_tale()\n",
        "    if fairy_tale is None:\n",
        "        return\n",
        "\n",
        "    print(\"\\n=== AI-Generated Fairy Tale (Russian) ===\\n\")\n",
        "    print(fairy_tale)\n",
        "\n",
        "    # 2. Pick background music based on user themes\n",
        "    if themes is None:\n",
        "        bg_music = DEFAULT_BG_MUSIC\n",
        "    else:\n",
        "        bg_music = pick_background_music(themes)\n",
        "\n",
        "    # 3. Convert the generated story to speech\n",
        "    narration_file = text_to_speech_coqui(fairy_tale, output_path=\"fairy_tale.wav\")\n",
        "    if narration_file is None:\n",
        "        return\n",
        "\n",
        "    # 4. Mix TTS narration with background music\n",
        "    final_output = \"final_fairy_tale_mix.wav\"\n",
        "    mix_audio_files(\n",
        "        narration_path=narration_file,\n",
        "        background_path=bg_music,\n",
        "        output_path=final_output,\n",
        "        music_volume_db=-15,    # reduce music volume by 15 dB\n",
        "        fade_out_ms=3000        # 3 second fade at the end\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Done! ===\")\n",
        "    print(f\"Your final narrated fairy tale with background music is: {final_output}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
